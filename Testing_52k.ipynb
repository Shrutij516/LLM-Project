{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da2d3c50",
      "metadata": {
        "id": "da2d3c50"
      },
      "source": [
        "# Inference Notebook\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e8e06e0",
      "metadata": {
        "id": "8e8e06e0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9794356b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9794356b",
        "outputId": "371075c1-f0a8-4146-c2a4-a4d84274200d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.27.post2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.25.2)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->xformers) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->xformers) (12.1.105)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->xformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->xformers) (1.3.0)\n",
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git@nightly (from unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly)\n",
            "  Cloning https://github.com/unslothai/unsloth.git (to revision nightly) to /tmp/pip-install-pp9jj1ay/unsloth_ef889de8740f442b939ce16aa67c1f8d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-pp9jj1ay/unsloth_ef889de8740f442b939ce16aa67c1f8d\n",
            "  Running command git checkout -b nightly --track origin/nightly\n",
            "  Switched to a new branch 'nightly'\n",
            "  Branch 'nightly' set up to track remote branch 'nightly' from 'origin'.\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit ea0a49448dca64808734cff797e352a69236343c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.43.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (24.1)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.8.5)\n",
            "Requirement already satisfied: transformers>=4.43.2 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (4.43.3)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2.16.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.43.0)\n",
            "Requirement already satisfied: accelerate>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.32.1)\n",
            "Requirement already satisfied: trl<0.9.0,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.8.6)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.12.0)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.23.5)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.1.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (6.0.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (3.9.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (12.1.105)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (1.7.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git@nightly->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git@nightly) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U xformers --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install \"unsloth[kaggle-new] @git+https://github.com/unslothai/unsloth.git@nightly\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# This will prompt you to enter your token\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "1b928fc76f834f5d9a22647bf1908c07",
            "df535b43393845b087bbcbaa30dd8c23",
            "c282afaf8a6f4b4f859b6e78641d35d1",
            "0d14aa4b1ea5414b927d70f2d692c306",
            "4279b863d26d42ff81dc6473c319e091",
            "f0b911bfbc354ccc90ed3d9b07458f90",
            "542bd0991b054025a7987313533598b6",
            "e30406f0bb4a4033855cfcd919174591",
            "c1bcea450b2242609e1f479e99c6eb8b",
            "62046bc7388a4748a22c0d0e95cdc991",
            "737264a4d1af4905baaebf549250c29a",
            "10935ba1cf85451e896b65aa798b5437",
            "2c9937d750c84e249096b8fa8f1a7422",
            "59bf2cb7513442c5b11dd6623b65905e",
            "990e3816a51c467686bad25268ff2d03",
            "fdc9e836f99b41f98c04e617470d14fa",
            "ea7dd54426e747209934832dd0cf451c",
            "05073e6c5ec24c4c8f8e1d7f4cf1738c",
            "825c70bb965f4478aa2ee67fd906ba04",
            "7fb04f1906ad4f148eb317e294adaeca",
            "f496c15e64bd4ea2819cc385ace39d17",
            "b3a5c18bfcf0490f871837b00b8b49ea",
            "f606abc4236d42b08d65ef04a158cf3e",
            "f522e047cb5c48e7ad3ef910e8b25d5d",
            "504acc2cad154b1bae9774e3d780ebb1",
            "4178034e006d40e1a681b302a2c96568",
            "8e447d4b89f64cb09e9d9f7203160b6e",
            "7da167eb7d5e4f27a19b492b1c9015a8",
            "c3292d7b49694c68b59ef7d30e26bcac",
            "65dbf58c30154a638c4ff2529193aa3e",
            "c7102b0115a2475c8802f5899531fd03",
            "0277f13a4dc9411dafaf45fb6e328bf0",
            "5176c23a0f2d4972aae1d1164df26a39",
            "eef9b718d5c148b88c891b0b610b4106",
            "4daf13b7084b456db738d0a41f294c7c",
            "12817bf74b8448eb955d32b7ddcbdb79",
            "94a12b94dbd246959f0974077dc76fac",
            "2539d614c10e4ae3bf38b6ecf7e360c8",
            "8667b1b65aac412babfbe4b947553e70",
            "672d75d606b64ea1a1fd14a74595566d",
            "01bea79d11ff431297b907387b940b27",
            "0d972984d5384d5eb047d0833a5202f6",
            "8ff5da450c86451294855fb6e5faf9ef",
            "8f1baebae1044cffaf4f85a6eab78cf7",
            "fd3074e3def8403386778fdd7ae031d1",
            "50eea668c45545369202083f72c0e97c",
            "194f52587e744de29bac1ab9e8ffd4ae"
          ]
        },
        "id": "Pgn_O0XPPDBe",
        "outputId": "bbd074b3-c853-46ee-e48a-f8731aadf059"
      },
      "id": "Pgn_O0XPPDBe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b928fc76f834f5d9a22647bf1908c07"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!mamba install --force-reinstall aiohttp -y\n",
        "!pip install -U \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "\n",
        "# Temporary fix for https://github.com/huggingface/datasets/issues/6753\n",
        "!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "hnI2lTOVF3Hu"
      },
      "id": "hnI2lTOVF3Hu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f5f0d30-b7ca-4800-ad93-5e0558836686",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "5251f2b5fa2e4ddcafc3ac0aa46dc909",
            "634f934513dc465f990362f3e320ff94",
            "213f705b215f41aa9c378fc7f049c067",
            "544289e107fd4d4ca081c456a18cfe0e",
            "9ea2e58baead4d50b7bc367c36f50aa6",
            "2304aa50af6a4666879cadd8eb8021a3",
            "da9f4f5410e94bf68ece02a82cb0f1f8",
            "ab32871895a2446297f4a15f415d4340",
            "f516f2ad31ac41e4af4731f3fefd933f",
            "9ba1a3c05d584f6ab4893bf738fb9490",
            "315148985681451fa52a4e8e3a7d94f6"
          ]
        },
        "id": "7f5f0d30-b7ca-4800-ad93-5e0558836686",
        "outputId": "6703dcde-89da-4e7e-803e-0ecc7b7e42aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "==((====))==  Unsloth 2024.8: Fast Gemma patching. Transformers = 4.43.3.\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.25.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
            "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
            "`config.hidden_activation` if you want to override this behaviour.\n",
            "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5251f2b5fa2e4ddcafc3ac0aa46dc909"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.8 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = False # Use for 4bit quantization\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Omickeyee/Marathi_Gemma_7B_52k\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "\n",
        ")\n",
        "\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "465c039a",
      "metadata": {
        "id": "465c039a"
      },
      "source": [
        "#### Alpaca prompt format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cdf06b6-14b3-41b4-ae66-0f30778a561a",
      "metadata": {
        "id": "2cdf06b6-14b3-41b4-ae66-0f30778a561a"
      },
      "outputs": [],
      "source": [
        "alpaca_prompt = \"\"\"\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f90ee8e",
      "metadata": {
        "id": "3f90ee8e"
      },
      "source": [
        "#### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d6175de",
      "metadata": {
        "id": "8d6175de"
      },
      "source": [
        "##### Example-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56de1a20-928f-4848-9fac-847ca1002502",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56de1a20-928f-4848-9fac-847ca1002502",
        "outputId": "5383e6f7-3bf2-436e-aefd-bc0f7f4714b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nTranslate following sentence to Marathi.\\n\\n### Input:\\nIndia is a great country.\\n\\n### Response:\\nभारत एक अद्भुत देश आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Translate following sentence to Marathi.\",\n",
        "        \"India is a great country.\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rwH4Jrqj8eco"
      },
      "id": "rwH4Jrqj8eco",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rl5WyUKw8eZx"
      },
      "id": "Rl5WyUKw8eZx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारतातील प्राचीन वैज्ञानिक आणि गणितज्ञ कोणते होते?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 100, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795dd126-4f3a-4d67-f026-20079627b755",
        "id": "-5qyP0al88Pv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारतातील प्राचीन वैज्ञानिक आणि गणितज्ञ कोणते होते?\\n\\n### Input:\\n\\n\\n### Response:\\nभारतातील प्राचीन वैज्ञानिक आणि गणितज्ञांमध्ये अनेक महान होते. काही प्रसिद्ध व्यक्तींमध्ये अरविंद शास्त्रज्ञ, अल्बर्ट आइन्स्टाईन, अणु भौतिकशास्त्रज्ञ आणि गणितज्ञ, सत्येनान, कर्नल सार्वत्रिक, कर्नल सार्वत्रिक, अणु भ']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "id": "-5qyP0al88Pv"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारताच्या राष्ट्रीय ध्वजाचे रंग कोणते आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98-YOi_3fO8z",
        "outputId": "07d920a3-7923-49d4-97ea-d2584150a3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारताच्या राष्ट्रीय ध्वजाचे रंग कोणते आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nभारताचा ध्वज पांढरा, नारिंगी आणि हिरवा असतो.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "id": "98-YOi_3fO8z"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"महाराष्ट्रातील सर्वाधिक उच्च शिखर कोणता आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy5ijbwrk__y",
        "outputId": "0d143e12-6a09-46a8-b85e-b21fb819b1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nमहाराष्ट्रातील सर्वाधिक उच्च शिखर कोणता आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nमहाराष्ट्रातील सर्वाधिक उच्च शिखर माथ्यावर आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "id": "Oy5ijbwrk__y"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारतीय स्वातंत्र्यलढा कधी सुरू झाला?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps-w6vbZk_9d",
        "outputId": "a6c5a78f-1491-48db-feaa-111dd6b0bb03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारतीय स्वातंत्र्यलढा कधी सुरू झाला?\\n\\n### Input:\\n\\n\\n### Response:\\nभारतीय स्वातंत्र्य लढा 1947 मध्ये सुरू झाला.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "id": "ps-w6vbZk_9d"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारतातील सर्वाधिक प्रचलित खेळ कोणते आहेत?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IWrR799k_6w",
        "outputId": "1f64458b-7701-49a1-c210-07239918be90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारतातील सर्वाधिक प्रचलित खेळ कोणते आहेत?\\n\\n### Input:\\n\\n\\n### Response:\\nभारतातील सर्वाधिक प्रचलित खेळ म्हणजे क्रिकेट.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "id": "4IWrR799k_6w"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारतातील सर्वाधिक मोठे राष्ट्रीय उद्यान कोणते आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpzWKlR0k_1X",
        "outputId": "8927c460-372d-46be-8aa7-6031dc27fc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारतातील सर्वाधिक मोठे राष्ट्रीय उद्यान कोणते आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nभारतातील सर्वात मोठे राष्ट्रीय उद्यान कॅनारा नॅशनल पार्क आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "id": "zpzWKlR0k_1X"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"मुंबईतील सर्वाधिक प्रसिद्ध देवस्थान कोणते आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9im9gO2k_yW",
        "outputId": "86a89608-8197-421c-a518-9c6229a45804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nमुंबईतील सर्वाधिक प्रसिद्ध देवस्थान कोणते आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nमुंबईतील सर्वात प्रसिद्ध देवस्थान म्हणजे ताजमहाल.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "id": "s9im9gO2k_yW"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारताची सर्वाधिक वजनदार निवडणुक कोणती होते?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB1fVYKhk_vO",
        "outputId": "fe13a71a-9b47-49b2-8f65-df1323ba75c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारताची सर्वाधिक वजनदार निवडणुक कोणती होते?\\n\\n### Input:\\n\\n\\n### Response:\\nभारताची सर्वाधिक वजनदार निवडणूक 1951 मध्ये झाली होती.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "id": "iB1fVYKhk_vO"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारतातील सर्वाधिक उच्च धरोहर कोणता आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjqMUfvek_sO",
        "outputId": "522b0e12-a053-46dd-baea-eef97ae5ba7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारतातील सर्वाधिक उच्च धरोहर कोणता आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nभारतातील सर्वाधिक उच्च धरोहर म्हणजे मुंबई, ज्याची अंदाजे लोकसंख्या 11 दशलक्ष आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "id": "HjqMUfvek_sO"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारतीय इतिहासातील प्रमुख क्रांती कोणती झाली?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcZJ4btHk_o-",
        "outputId": "ee8194e4-d588-4695-f1e7-d34b7d3dec07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारतीय इतिहासातील प्रमुख क्रांती कोणती झाली?\\n\\n### Input:\\n\\n\\n### Response:\\nभारतीय इतिहासातील महत्त्वाची क्रांती म्हणजे स्वातंत्र्य चळवळ.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "id": "tcZJ4btHk_o-"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका बोक्समध्ये २५ फेकण्यांच्या खेळाची अंश आहे, पांढर फेकण्यांच्या खेळाची अंश किती आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNJabvCDk_lO",
        "outputId": "afc0d645-d241-4de2-c840-6aae7ad21f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका बोक्समध्ये २५ फेकण्यांच्या खेळाची अंश आहे, पांढर फेकण्यांच्या खेळाची अंश किती आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nपांढरा फेकण्यांच्या खेळाची अंश 1/12 आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "id": "rNJabvCDk_lO"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"४ च्या २/५ किती असेल?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1YoI6DTk_hy",
        "outputId": "8335d359-6930-4cd4-afa8-9894f694accd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\n४ च्या २/५ किती असेल?\\n\\n### Input:\\n\\n\\n### Response:\\n0.8<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "id": "P1YoI6DTk_hy"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एक समुद्री जहाज २५० किलोमीटर चालतो, त्याच्या दुरीची २०% पूर्ण झाल्यास त्याच्या किती किलोमीटर उरते?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G9Oh9t8k_eZ",
        "outputId": "852944e8-306f-41f9-8234-78c34f687cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएक समुद्री जहाज २५० किलोमीटर चालतो, त्याच्या दुरीची २०% पूर्ण झाल्यास त्याच्या किती किलोमीटर उरते?\\n\\n### Input:\\n\\n\\n### Response:\\n250 किलोमीटर चाललेल्या समुद्राच्या जहाजाचे उर्वरित किलोमीटर 200 किलोमीटर आहेत.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "id": "-G9Oh9t8k_eZ"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"वर्गच्या परिमाणाची अंश किती आहे ज्याचा क्षेत्रफल ८१ चौकोर किलोमीटर आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdMTB5VZk_a9",
        "outputId": "801f8e15-7573-4c9e-ab1b-0a5f0dd1ca2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nवर्गच्या परिमाणाची अंश किती आहे ज्याचा क्षेत्रफल ८१ चौकोर किलोमीटर आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nवर्गच्या परिमाणाची अंश 1 आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "id": "gdMTB5VZk_a9"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"१२ वर्षांच्या बालाचे उंच किती असेल जर तो जन्म घेतला असेल जितकी त्याच्या मातेचा उंच ५ फुट आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1HQWwhDk_XX",
        "outputId": "dc347fd6-cd72-47ca-cf13-7411b3be0a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\n१२ वर्षांच्या बालाचे उंच किती असेल जर तो जन्म घेतला असेल जितकी त्याच्या मातेचा उंच ५ फुट आहे?\\n\\n### Input:\\n\\n\\n### Response:\\n12 वर्षांच्या बालाचे उंची 5 फूट 11 इंच असेल.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "id": "X1HQWwhDk_XX"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"३०० रुपये किती मुद्दे २५ फेकण्यात वाटतात?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJpyDBKDk_UU",
        "outputId": "9310771c-4e0f-4b95-b537-5970d26f3b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\n३०० रुपये किती मुद्दे २५ फेकण्यात वाटतात?\\n\\n### Input:\\n\\n\\n### Response:\\n300 रुपये म्हणजे 100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000']"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "id": "kJpyDBKDk_UU"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका बाराची किंमत २५ रुपये वाढली. त्या बाराची नवीन किंमत किती आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlr01UsZk_Qk",
        "outputId": "8621f7ab-ca2a-43a3-c524-48f015ba2901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका बाराची किंमत २५ रुपये वाढली. त्या बाराची नवीन किंमत किती आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nबाराची नवीन किंमत 27.50 रुपये आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "id": "Jlr01UsZk_Qk"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"८५ अंकाची अंश किती आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvenddLMk_M7",
        "outputId": "046a0011-d70e-4625-e2a2-b35ba82510de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\n८५ अंकाची अंश किती आहे?\\n\\n### Input:\\n\\n\\n### Response:\\n0.01010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101']"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "id": "PvenddLMk_M7"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"१२ मिनिटांमध्ये ६० फूट चालतोत. त्याची औसत वेग किती असेल?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcY_zFCZk_JT",
        "outputId": "97188d21-9184-4fe6-b12c-69f5a21f8914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\n१२ मिनिटांमध्ये ६० फूट चालतोत. त्याची औसत वेग किती असेल?\\n\\n### Input:\\n\\n\\n### Response:\\n12 मिनिटांमध्ये 60 फूट चालताना त्याची सरासरी वेग 5 फूट प्रति मिनिट असेल.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "id": "QcY_zFCZk_JT"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका जलदपातची उंची १० मीटर आहे. ती किती फूट उचलते?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_yZ90v9k_DI",
        "outputId": "3d584abb-7012-4f93-afcc-04edee26d0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका जलदपातची उंची १० मीटर आहे. ती किती फूट उचलते?\\n\\n### Input:\\n\\n\\n### Response:\\n10 मीटर उंची असलेली जलदपात 32 फूट उंच आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "id": "V_yZ90v9k_DI"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारताच्या दरबारी वस्त्र तयार करण्याची कला कोणत्या शहरात प्राचीनपणे असेल?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0IXM6vObqTr",
        "outputId": "6a3b5a5f-2ba7-4115-bcb6-ff2f9017de09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारताच्या दरबारी वस्त्र तयार करण्याची कला कोणत्या शहरात प्राचीनपणे असेल?\\n\\n### Input:\\n\\n\\n### Response:\\nभारताच्या दरबारी वस्त्र तयार करण्याची कला प्राचीनपणे मुंबई, भारतात असेल.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "id": "L0IXM6vObqTr"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"छत्रपती शिवाजी महाराजांचे जन्म कुठे झाले?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew8GD-2DbqRB",
        "outputId": "e406f826-7244-466d-82b6-22a608a8be7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nछत्रपती शिवाजी महाराजांचे जन्म कुठे झाले?\\n\\n### Input:\\n\\n\\n### Response:\\nमहाराजांचे जन्म कुठे झाले?<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "id": "ew8GD-2DbqRB"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारतातील सबसे प्रमुख महानगर कोणते आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4Hv7ZAqbqOO",
        "outputId": "518f729c-ffa8-45cb-a7d3-c48f8fc3a8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारतातील सबसे प्रमुख महानगर कोणते आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nमुंबई हे भारतातील सर्वात मोठे महानगर आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "id": "o4Hv7ZAqbqOO"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"गणपतीच्या उत्सवातील सर्वाधिक प्रमुख ठिकाण कोणते आहेत?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4giKad55bqK5",
        "outputId": "7b927ad2-b55d-4108-f673-16aecb505a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nगणपतीच्या उत्सवातील सर्वाधिक प्रमुख ठिकाण कोणते आहेत?\\n\\n### Input:\\n\\n\\n### Response:\\nगणपतीच्या उत्सवातील सर्वाधिक प्रमुख ठिकाणे म्हणजे मंदिर, मंदिर आणि मंदिर.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "id": "4giKad55bqK5"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"महाराष्ट्राच्या सर्वाधिक प्रसिद्ध लोकनृत्य कोणते आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7RY5daVbqIO",
        "outputId": "d86b9ac9-5722-4bee-c96d-56ea182c7ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nमहाराष्ट्राच्या सर्वाधिक प्रसिद्ध लोकनृत्य कोणते आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nमहाराष्ट्राचे सर्वात प्रसिद्ध लोकनृत्य म्हणजे \"द कॅन्टन\" नावाचे लोकनृत्य.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "id": "M7RY5daVbqIO"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"विश्व इतिहासातील प्रमुख क्रांती कोणती होती?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChgIjTbVbqDM",
        "outputId": "b2c86580-9aa1-44e5-b849-1cc8a53ad37b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nविश्व इतिहासातील प्रमुख क्रांती कोणती होती?\\n\\n### Input:\\n\\n\\n### Response:\\n1812 ते 1814 पर्यंतच्या युद्धात युरोपियन साम्राज्यांच्या विस्तारामुळे आणि अमेरिकन क्रांतीमुळे अमेरिकन क्रांती ही एक प्रमुख क्रांती होती.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "id": "ChgIjTbVbqDM"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"गृहयुद्धांच्या कारणांपासून भारतात कोणत्या शतकात साम्राज्यिक परिस्थिती बदलली?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-JhTCLybqAl",
        "outputId": "718d3cb4-1535-4d69-c0e7-7eea85557355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nगृहयुद्धांच्या कारणांपासून भारतात कोणत्या शतकात साम्राज्यिक परिस्थिती बदलली?\\n\\n### Input:\\n\\n\\n### Response:\\nभारतात गृहयुद्धांच्या कारणांपासून साम्राज्यवादाचा काळ बदलला. गृहयुद्धांमुळे भारतातील अनेक राज्यांच्या स्वातंत्र्याला धक्का बसला आणि अनेकांना आता भारतातील एकमेव राज्यांच्या राज्यात विभागले गेले. यामुळे भारतातील अनेक राज्यांच्या आर्थिक आणि सामाजिक परिस्थितीत लक्षणीय घट झाली आणि भारतातील अनेक शेतकरी आणि व्यापारी गरिबीत पडले. यामुळे भारतातील अनेक शेतकऱ्यांच्या मालमत्तेचे नुकसान देखील झाले आणि भारतातील अनेक शेतकऱ्यांच्या मालमत्तेचा नाश झाला.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "id": "3-JhTCLybqAl"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारताच्या पार्लमेंटाची उच्च सदन कोणती आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig2PPEc_wHxE",
        "outputId": "1cdf92ec-0698-4417-b80a-c5382555934e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारताच्या पार्लमेंटाची उच्च सदन कोणती आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nभारताच्या पार्लमेंटाची उच्च सदन नरेंद्र मोदी आहेत.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "id": "Ig2PPEc_wHxE"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारताच्या स्वतंत्रतेच्या संघर्षातील मुख्य क्रियाकलाप कोणते होते?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGRkv_-WwHuZ",
        "outputId": "c6d9c4d4-9873-4579-fa2d-082b2569e785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारताच्या स्वतंत्रतेच्या संघर्षातील मुख्य क्रियाकलाप कोणते होते?\\n\\n### Input:\\n\\n\\n### Response:\\nभारताच्या स्वातंत्र्य चळवळीतील मुख्य क्रियाकलापांमध्ये 1940 च्या दशकाच्या मध्यात भारतातील ब्रिटिश राजवटीविरुद्धच्या लढाईंचा समावेश होता. या लढाईंमध्ये भारतातील नागरिकांनी ब्रिटिशांविरुद्ध लढले आणि अखेरीस भारताची स्वातंत्र्य घोषणा करण्यात आली.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "id": "wGRkv_-WwHuZ"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारतातील सर्वाधिक प्रसिद्ध धार्मिक स्थळ कोणतं आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp-BY2rewHr6",
        "outputId": "49e93159-5310-4195-d649-4c1bbb1ba98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारतातील सर्वाधिक प्रसिद्ध धार्मिक स्थळ कोणतं आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nभारतातील सर्वात प्रसिद्ध धार्मिक स्थळ म्हणजे ताजमहाल.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "id": "jp-BY2rewHr6"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आणखी किती प्रकारे आहेत डेटा स्टोरेज डिवाइसेस?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT7MlbinwHpR",
        "outputId": "f563730f-f680-481f-a609-105025238440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआणखी किती प्रकारे आहेत डेटा स्टोरेज डिवाइसेस?\\n\\n### Input:\\n\\n\\n### Response:\\nडेटा स्टोरेज उपकरणांचे अनेक प्रकार आहेत. यामध्ये क्लाउड स्टोरेज, हार्ड ड्राइव्ह, सॉलिड स्टेट ड्राइव्ह, ऑप्टिकल ड्राइव्ह, कॅमेरा, स्टोरेज कार्ड आणि इतर डिव्हाइसेस यांचा समावेश होतो.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "id": "GT7MlbinwHpR"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"सोलर एनर्जीचा वापर करताना असा कोणता उपकरण वापरला जातो?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEnQ5LGSwHmK",
        "outputId": "e9b43b79-3c3c-44c1-ee9c-c3b036e85cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nसोलर एनर्जीचा वापर करताना असा कोणता उपकरण वापरला जातो?\\n\\n### Input:\\n\\n\\n### Response:\\nसौर ऊर्जेचा वापर करताना वापरलेले एक उपकरण म्हणजे सौर पॅनेल.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "id": "LEnQ5LGSwHmK"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"इंटरनेट ऑफ थिंग्स (IoT) हे काय आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h6mp5gpwHjl",
        "outputId": "1ac51d75-751e-4c9b-91be-859d43a4a036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nइंटरनेट ऑफ थिंग्स (IoT) हे काय आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nइंटरनेट ऑफ थिंग्ज (IoT) हे भौतिक वस्तूंचे नेटवर्क आहे जे इंटरनेटशी कनेक्ट केलेले आहे आणि डेटा सामायिक करण्यासाठी एकमेकांशी संवाद साधते. IoT उपकरणांमध्ये स्मार्ट होम ऑटोमेशन, वाहने, औद्योगिक उपकरणे आणि बरेच काही यांचा समावेश होतो.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "id": "9h6mp5gpwHjl"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"अणुक्रमण आणि अणुस्थिती किती वेगाने चालतात?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiIwhAkEwHe5",
        "outputId": "dc0db12c-be49-46af-a11b-4acba592b27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nअणुक्रमण आणि अणुस्थिती किती वेगाने चालतात?\\n\\n### Input:\\n\\n\\n### Response:\\nअणुक्रमण आणि अणुस्थिती अनेक वेगाने चालतात. अणुक्रमणांचा वेग अणुक्रमांक आणि अणुक्रमांक यांच्यातील प्रमाणात असतो, तर अणुस्थिती अणुक्रमांक आणि अणुक्रमांक यांच्यातील प्रमाणात असते. अणुक्रमांक आणि अणुक्रमांक यातील प्रमाण अणुक्रमांक आणि अणुक्रमांक यांच्यातील प्रमाणात असते.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "id": "SiIwhAkEwHe5"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एक्यूटेन आणि स्कॉलारशिपचा मुख्य फरक काय आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWxmR5ukwHac",
        "outputId": "78405f7c-10d9-48be-b81f-168206d96958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएक्यूटेन आणि स्कॉलारशिपचा मुख्य फरक काय आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nएक्यूटेन आणि स्कॉलारशिपचा मुख्य फरक म्हणजे ते ज्या प्रकारचे शिकवणी देतात. एक्यूटेन शिकवणी अधिक आकर्षक आणि आकर्षक असतात, तर स्कॉलारशिप शिकवणी अधिक तार्किक आणि तार्किक असतात.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "id": "AWxmR5ukwHac"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एक्सरे रे सूर्य तेलाचा वापर काय होतो?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9zxULyiwHYH",
        "outputId": "5fda31ce-9a7e-492b-e420-49e0ae862a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएक्सरे रे सूर्य तेलाचा वापर काय होतो?\\n\\n### Input:\\n\\n\\n### Response:\\nएक्सरे रे सूर्य तेलाचा वापर केला जातो ज्याला \"रेड-ओव्हर\" म्हणतात. हे एक रेडिओलॉजिकल तंत्र आहे जे पेशींच्या आकारात आणि आकारात बदल करून कर्करोगाचे निदान करण्यासाठी वापरले जाते.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "id": "i9zxULyiwHYH"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"अम्बुलेंस एमआरआयचा वापर कशा असतो?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_wI4sYHwHVh",
        "outputId": "60854020-0867-4d33-976c-7001ef3d452f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nअम्बुलेंस एमआरआयचा वापर कशा असतो?\\n\\n### Input:\\n\\n\\n### Response:\\nअम्बुलेंस एमआरआयचा वापर अनेक प्रकारे केला जातो. हे वैद्यकीय इमेजिंगसाठी एक प्रकारचे स्कॅनिंग मशीन म्हणून वापरले जाऊ शकते जे वैद्यकीय व्यावसायिकांना पेशींच्या रचनात्मक वैशिष्ट्यांबद्दल अंतर्दृष्टी प्रदान करते. हे एक प्रकारचे स्कॅनिंग मशीन म्हणून देखील वापरले जाऊ शकते जे वैद्यकीय व्यावसायिकांना पेशींच्या रचनात्मक वैशिष्ट्यांबद्दल अंतर्दृष्टी प्रदान करते. अम्बुलेंस एमआरआयचा वापर पेशींच्या रचनात्मक वैशिष्ट्यांचे निरीक्षण करण्यासाठी देखील केला जाऊ शकतो.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "id": "N_wI4sYHwHVh"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"फोटोवॉल्टेक एनर्जी तयार करण्यासाठी कोणत्या साहित्यातील उपकरणे वापरली जातात?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5kL88QuwHS7",
        "outputId": "8fbf028c-97dc-4eba-85d7-f389e8f17a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nफोटोवॉल्टेक एनर्जी तयार करण्यासाठी कोणत्या साहित्यातील उपकरणे वापरली जातात?\\n\\n### Input:\\n\\n\\n### Response:\\nफोटोवॉल्टेक एनर्जी तयार करण्यासाठी वापरलेला साहित्य म्हणजे सिलिकॉन, सिलिकेट किंवा सिलिकेट सारख्या अर्धसंवाहक सामग्रीपासून बनलेले पेशी.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "id": "l5kL88QuwHS7"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"अणु युद्धांमध्ये दोन्हीं कोणत्या देशांची सर्वाधिक यशस्वीता होते?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTzRUhRcwHOI",
        "outputId": "6953a463-e80a-42ba-ccab-c65082f49791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nअणु युद्धांमध्ये दोन्हीं कोणत्या देशांची सर्वाधिक यशस्वीता होते?\\n\\n### Input:\\n\\n\\n### Response:\\nअणुयुद्धांमध्ये दोन्ही देशांनी यशस्वी अणुयुद्धांचा अनुभव घेतला आहे. जर्मनीने 1945 मध्ये पहिले यशस्वी अणुयुद्ध केले, तर जपानने 1945 मध्ये दुसरे यशस्वी अणुयुद्ध केले.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "id": "iTzRUhRcwHOI"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"डिजिटल गणित ची मूळ एकायण तज्ज्ञान आणि कॉम्प्यूटर सायन्स ची कोणती काही संबंधांतली माहिती आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyEKYw5owHLN",
        "outputId": "98c38f5a-498c-43c3-c607-6835086e3cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nडिजिटल गणित ची मूळ एकायण तज्ज्ञान आणि कॉम्प्यूटर सायन्स ची कोणती काही संबंधांतली माहिती आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nडिजिटल गणित ही गणितीय संकल्पनांची एक प्रणाली आहे जी डिजिटल मशीनद्वारे केली जाते. कॉम्प्युटर सायन्स आणि मशीन लर्निंग या दोन्ही क्षेत्रांमध्ये डिजिटल गणित महत्त्वपूर्ण आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "id": "lyEKYw5owHLN"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका व्यक्तीने प्रत्येका वारच्या दोन दिवसांत ३० मिनिटे अभ्यास करतो. एका महिन्यात मोठ्या कधी खूप कमी वेळ अभ्यास केल्यावर, प्रत्येका वारच्या अभ्यासाची वेळ काय आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDI6fgV10BBS",
        "outputId": "9644567d-4799-4c76-f754-10d137664326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका व्यक्तीने प्रत्येका वारच्या दोन दिवसांत ३० मिनिटे अभ्यास करतो. एका महिन्यात मोठ्या कधी खूप कमी वेळ अभ्यास केल्यावर, प्रत्येका वारच्या अभ्यासाची वेळ काय आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nएका महिन्यात मोठ्याने कमी वेळात अभ्यासाची वेळ प्रत्येका वारच्या दोन दिवसांत ३० मिनिटे आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "id": "xDI6fgV10BBS"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका गोडीने ३६० लीटर पाणी प्रवाहित केले. पाणी निवडण्याच्या योग्यतेसाठी पाणीची एका घरणीत ३ खांब लागतात. पाणी तयार करण्यासाठी २५ खांब वापरल्यावर, किती लीटर पाणी तयार होईल?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAEzZ8sb0A_D",
        "outputId": "973aa9fd-139d-4db4-ae28-d67ab413f918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका गोडीने ३६० लीटर पाणी प्रवाहित केले. पाणी निवडण्याच्या योग्यतेसाठी पाणीची एका घरणीत ३ खांब लागतात. पाणी तयार करण्यासाठी २५ खांब वापरल्यावर, किती लीटर पाणी तयार होईल?\\n\\n### Input:\\n\\n\\n### Response:\\nपाणी तयार करण्यासाठी 25 खांब वापरल्यास, 360 लीटर पाणी तयार होईल.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "id": "cAEzZ8sb0A_D"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका जम्याच्या सर्वात मोठ्या कोणाला ६० डिग्री असल्याचे माहित आहे. अण्णाना काय डिग्री असते?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOTkBFcA0A8-",
        "outputId": "3b70247b-c0d7-476d-b931-cb45bffc5dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका जम्याच्या सर्वात मोठ्या कोणाला ६० डिग्री असल्याचे माहित आहे. अण्णाना काय डिग्री असते?\\n\\n### Input:\\n\\n\\n### Response:\\nअण्णानाची सर्वात मोठी जमायची 60 डिग्री आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "id": "cOTkBFcA0A8-"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका पेटया मध्ये १२० अंड्या आहेत. अण्णाने त्यातून १/५ अंडे घेतले. उर्णनबाजीतून बाकी किती अंडे नक्की आहेत?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBKoQebK0A6C",
        "outputId": "e339ab17-a368-4262-cd61-b41f4ec97f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका पेटया मध्ये १२० अंड्या आहेत. अण्णाने त्यातून १/५ अंडे घेतले. उर्णनबाजीतून बाकी किती अंडे नक्की आहेत?\\n\\n### Input:\\n\\n\\n### Response:\\nअण्णाकडे अंदाजे 110 अंडे आहेत.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "id": "SBKoQebK0A6C"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका शाळेत १२० विद्यार्थ्यांच्या संख्येचा ३/४ भाग वयोमान अ १५ वर्षांच्या अधिक आहे. अण्णाना संख्येची वय माहित करा.\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8p79lrV0A3F",
        "outputId": "b5585dd6-76d8-469b-d8fa-af580e2550cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका शाळेत १२० विद्यार्थ्यांच्या संख्येचा ३/४ भाग वयोमान अ १५ वर्षांच्या अधिक आहे. अण्णाना संख्येची वय माहित करा.\\n\\n### Input:\\n\\n\\n### Response:\\nशाळेत १२० विद्यार्थ्यांच्या संख्येचा ३/४ भाग वयाचा अंदाजे १५ वर्षांचा आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "id": "m8p79lrV0A3F"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका विज्ञानाच्या प्रकल्पासाठी ३६० विद्यार्थ्यांनी ३० दिवसांसाठी वार्षिक पुनरावृत्ती घेतली. उदाहरणार्थ, किती दिवसांसाठी पुनरावृत्ती घेतली?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0ZV630V0A0o",
        "outputId": "f2d91713-bf21-442d-e748-8e9b1356f106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका विज्ञानाच्या प्रकल्पासाठी ३६० विद्यार्थ्यांनी ३० दिवसांसाठी वार्षिक पुनरावृत्ती घेतली. उदाहरणार्थ, किती दिवसांसाठी पुनरावृत्ती घेतली?\\n\\n### Input:\\n\\n\\n### Response:\\n360 विद्यार्थ्यांनी 30 दिवसांसाठी पुनरावृत्ती केली.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "id": "L0ZV630V0A0o"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका देवाचे उंच ५०० मीटर आहे. तो देवाच्या आत अगदी उंच उचलतो जेणेकरून १००० मीटर वाढलेल्या वेळेत. त्याची आती किती वेगाने वाढते?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vWQY_h_0AyC",
        "outputId": "b2c7c176-d956-4aa8-944b-89b2264881a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका देवाचे उंच ५०० मीटर आहे. तो देवाच्या आत अगदी उंच उचलतो जेणेकरून १००० मीटर वाढलेल्या वेळेत. त्याची आती किती वेगाने वाढते?\\n\\n### Input:\\n\\n\\n### Response:\\nया देवाने आती 100 मीटर वेगाने वाढवले पाहिजे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "id": "7vWQY_h_0AyC"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका कॉलेजमध्ये ३६ टीचर आहेत. त्यांमध्ये १/४ ची एका गटात आधी २ वयोमान आहेत जे अशी दोन संख्या असतात जी संख्या २ च्या निर्दिष्ट भाग असतात. वयोमान काय असेल?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvJmy-p80Au_",
        "outputId": "25b40eac-3bba-4ddc-c306-72b64b5d0595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका कॉलेजमध्ये ३६ टीचर आहेत. त्यांमध्ये १/४ ची एका गटात आधी २ वयोमान आहेत जे अशी दोन संख्या असतात जी संख्या २ च्या निर्दिष्ट भाग असतात. वयोमान काय असेल?\\n\\n### Input:\\n\\n\\n### Response:\\nवयाच्या 1/4 च्या समतुल्य वयाचा अंदाज 16 वर्षांचा आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "id": "gvJmy-p80Au_"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका दिवसाच्या २४ तासांमध्ये व्यक्ती अशा रीतीने काम करतो की तो पूर्ण निर्दिष्ट काम करतो. त्यानुसार, किती वेळ तो काम करेल?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXoUD17p0Asb",
        "outputId": "39b42d7b-0c83-434f-9577-e6294313b54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका दिवसाच्या २४ तासांमध्ये व्यक्ती अशा रीतीने काम करतो की तो पूर्ण निर्दिष्ट काम करतो. त्यानुसार, किती वेळ तो काम करेल?\\n\\n### Input:\\n\\n\\n### Response:\\nएका दिवसाच्या 24 तासांमध्ये, व्यक्ती अंदाजे 10 तास काम करेल.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "id": "TXoUD17p0Asb"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"एका वस्तुने ३०% संबंधित तल्ला निगडलेला असतो. जर ते ६०० ग्रामाचे असते, तर तल्ला किती ग्रामाचे असेल?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx2XE3ZU0Ap2",
        "outputId": "7572a42c-0011-4609-890e-b3f68b3b9f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nएका वस्तुने ३०% संबंधित तल्ला निगडलेला असतो. जर ते ६०० ग्रामाचे असते, तर तल्ला किती ग्रामाचे असेल?\\n\\n### Input:\\n\\n\\n### Response:\\n60 ग्रॅम<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "id": "nx2XE3ZU0Ap2"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या मित्राला आपल्या सहकाऱ्याला विद्यापीठातील प्राथमिक शिक्षण योजनेचा उल्लेख करताना काही मदत हवी असल्यास आपण कसे सांगणार?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqNHSNHu0AnG",
        "outputId": "019195ca-35b6-4183-f912-8429f396f78e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या मित्राला आपल्या सहकाऱ्याला विद्यापीठातील प्राथमिक शिक्षण योजनेचा उल्लेख करताना काही मदत हवी असल्यास आपण कसे सांगणार?\\n\\n### Input:\\n\\n\\n### Response:\\nप्रिय मित्र,\\n\\nमाझ्या सहकाऱ्याने मला विद्यापीठातील प्राथमिक शिक्षणाच्या योजनेचा उल्लेख केला आहे. हे एक उत्तम योजनेचे संशोधन करण्यासाठी एक उत्तम संधी आहे. यात विविध क्षेत्रांचा समावेश आहे ज्यात तुम्ही स्वारस्य असू शकता, जसे की विज्ञानाचे क्षेत्र किंवा मानवी संसाधन व्यवस्थापन. याव्यतिरिक्त, विद्यापीठाच्या विविध संसाधनांचा लाभ घ्या - जसे की कौशल्य प्रशिक्षण आणि इंटर्नशिप.\\n\\nमी या योजनेचे संशोधन करण्यासाठी उत्सुक आहे आणि मला खात्री आहे की ती तुमच्यासाठी एक उत्तम निवड असेल.\\n\\nप्रामाणिकपणे,\\n[तुमचे नाव]<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "id": "MqNHSNHu0AnG"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या कार्यालयात व्यक्तिचित्र काढताना आपल्याला निर्देशित केले आहे कार्यालयातील नियमांसंबंधीत प्रक्रिया आणि स्थिती समजलेल्या व्यक्तीला कसे मदत करणार?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3gz8hdi0Aku",
        "outputId": "39bd15d0-e1df-41ba-ff21-0aa2e297bda1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या कार्यालयात व्यक्तिचित्र काढताना आपल्याला निर्देशित केले आहे कार्यालयातील नियमांसंबंधीत प्रक्रिया आणि स्थिती समजलेल्या व्यक्तीला कसे मदत करणार?\\n\\n### Input:\\n\\n\\n### Response:\\nकार्यालयातील नियमांबद्दल प्रक्रिया आणि स्थिती समजून घेतल्याने व्यक्तीला कार्यालयातील नियमांबद्दल अधिक जाणून घेता येईल आणि कार्यालयातील नियमांबद्दल अधिक जाणून घेण्यासाठी त्यांच्या सहकाऱ्यांकडून प्रश्न विचारता येतील. याव्यतिरिक्त, कार्यालयातील नियमांबद्दल अधिक जाणून घेतल्याने व्यक्तीला काही विशिष्ट कार्ये किंवा प्रक्रिया कशी कराव्यात किंवा काय करावे याबद्दल अधिक माहिती मिळेल.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "id": "v3gz8hdi0Aku"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या क्लबमध्ये एक चालक बसून वेळ वाचण्यास समय वापरतो. एका दिवसात त्याचा वेळ किती वेळा असला आणि त्याचे बसणे आणि रुग्ण लावणे कसे समाधान करणार?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYyqWMP60Ah_",
        "outputId": "72edfd45-67a0-4950-fc96-83b7d26abde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या क्लबमध्ये एक चालक बसून वेळ वाचण्यास समय वापरतो. एका दिवसात त्याचा वेळ किती वेळा असला आणि त्याचे बसणे आणि रुग्ण लावणे कसे समाधान करणार?\\n\\n### Input:\\n\\n\\n### Response:\\nएक चालक बसून वेळ वाचवतो. एका दिवसात, त्याने 10 ते 15 रुग्णांना लावले पाहिजे आणि त्याने 10 ते 15 वेळा बसण्याची आवश्यकता असेल.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "id": "TYyqWMP60Ah_"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या विद्यापीठातील एक साधने अगदी खराब झाल्याने अद्याप अध्यापकांना समस्या झाली आहे. आपण कसे सांगणार त्यांना कसे ह्या समस्येसाठी त्याच्या नियुक्तीसाठी मदत करण्यासाठी?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaG3HnNo0AfN",
        "outputId": "d19b3dab-fe02-40a2-af9f-8fccba99ce4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या विद्यापीठातील एक साधने अगदी खराब झाल्याने अद्याप अध्यापकांना समस्या झाली आहे. आपण कसे सांगणार त्यांना कसे ह्या समस्येसाठी त्याच्या नियुक्तीसाठी मदत करण्यासाठी?\\n\\n### Input:\\n\\n\\n### Response:\\nअद्याप अध्यापकांना समस्या येत असल्याने, आम्ही त्यांच्या समस्येचे निराकरण करण्यासाठी प्रथम त्यांच्या समस्या समजून घेण्याचा प्रयत्न करू. आम्ही त्यांच्या समस्या समजून घेण्यासाठी आणि त्यांच्या समस्येचे निराकरण करण्यासाठी संभाव्य उपाय शोधण्यासाठी त्यांच्याशी बोलू. आम्ही त्यांच्या समस्या समजून घेण्यासाठी आणि त्यांच्या समस्येचे निराकरण करण्यासाठी त्यांच्याशी बोलण्यासाठी एक योजना तयार करू.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "id": "NaG3HnNo0AfN"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या कामाला आपल्या टीममध्ये बदल करण्याची आवश्यकता आहे. आपल्या टीमला विशेष नोंद केलेल्या गुणांच्या आधारे कोणते प्रोफाइल्स शोधायला सल्ला द्यायचे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ6082ky0Acu",
        "outputId": "f8a1617b-8342-4ac8-e0c5-0dd01fce9756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या कामाला आपल्या टीममध्ये बदल करण्याची आवश्यकता आहे. आपल्या टीमला विशेष नोंद केलेल्या गुणांच्या आधारे कोणते प्रोफाइल्स शोधायला सल्ला द्यायचे?\\n\\n### Input:\\n\\n\\n### Response:\\nआमच्या टीमला विशेष नोंद केलेल्या गुणांच्या आधारे, मी आमच्या टीमला संघटनात्मक आणि प्रेरक कौशल्ये शोधायला सल्ला देतो. संघटनात्मक कौशल्ये संघांना कार्यक्षमतेने कार्ये व्यवस्थापित करण्यास आणि प्रक्रिया सुव्यवस्थित करण्यास मदत करू शकतात, तर प्रेरक कौशल्ये संघांना प्रेरित करण्यास आणि प्रेरणा देण्यास मदत करू शकतात.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "id": "qJ6082ky0Acu"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या नेटवर्कमध्ये कोणत्या व्यक्तीला आपण नव्हे बळीर आणि आत्मविश्वास कमी मानतो? आपण काय करू शकता?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRsq_bG80AaC",
        "outputId": "0ff109c2-9e43-4c39-b1e6-8313c3b72633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या नेटवर्कमध्ये कोणत्या व्यक्तीला आपण नव्हे बळीर आणि आत्मविश्वास कमी मानतो? आपण काय करू शकता?\\n\\n### Input:\\n\\n\\n### Response:\\nआपल्या नेटवर्कमध्ये, काही लोक आपल्या कल्पना आणि कल्पना व्यक्त करण्यास कमी बळीर आणि आत्मविश्वास कमी मानतात. आम्ही त्यांच्याशी बोलण्याचा प्रयत्न करू शकतो आणि त्यांना त्यांच्या कल्पना व्यक्त करण्यास प्रोत्साहित करू शकतो.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "id": "TRsq_bG80AaC"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या कार्यालयात एक विभागाचे बोस अद्याप ३ महिन्यांपासून काम करत आहे. आपण कशीतरी समस्यांचा समाधान करणार आणि कशाप्रकारे त्याच्यावर पराभव नका करणार?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf1srlir0AXs",
        "outputId": "2a7251da-e545-4c89-d9e1-fd874a3db9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या कार्यालयात एक विभागाचे बोस अद्याप ३ महिन्यांपासून काम करत आहे. आपण कशीतरी समस्यांचा समाधान करणार आणि कशाप्रकारे त्याच्यावर पराभव नका करणार?\\n\\n### Input:\\n\\n\\n### Response:\\nआपल्या कार्यालयातील विभागाचे बोस अद्याप तीन महिन्यांपासून काम करत आहे. आपण त्याला त्याच्या कामाच्या दिशेने प्रेरित करण्यासाठी आणि त्याला त्याच्या कर्तृत्वाचा अभिमान वाटेल असे वातावरण तयार करण्यासाठी प्रोत्साहित केले पाहिजे. याव्यतिरिक्त, आम्ही त्याच्या कामगिरीचे निरीक्षण केले पाहिजे आणि त्याला त्याच्या कर्तृत्वाबद्दल अभिमान वाटेल असे वातावरण तयार करण्यासाठी त्याला अभिप्राय दिला पाहिजे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "id": "Wf1srlir0AXs"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या नात्यांमध्ये एका दिवसाच्या कोणत्या विचारात काही अभिप्रेरणा कसा दिल्याची सहाय्य करावी?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTR0Ms880AVH",
        "outputId": "eb1a4402-11b9-4e44-d44e-06349e09eea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या नात्यांमध्ये एका दिवसाच्या कोणत्या विचारात काही अभिप्रेरणा कसा दिल्याची सहाय्य करावी?\\n\\n### Input:\\n\\n\\n### Response:\\nआपल्या नात्यांमध्ये एका दिवसाच्या विचारात काही अभिप्रेरणा देण्यासाठी, आपल्याला आपल्या दैनंदिन जीवनातील छोट्या गोष्टी लक्षात ठेवावे लागतील ज्यामुळे आपल्याला आनंद मिळतो आणि आपल्याला एकमेकांशी जोडलेले राहण्यास मदत होते. आपल्या दिवसाची सुरुवात करण्यासाठी, आपल्या दिवसाची योजना करण्यासाठी आणि आपल्या दिवसाचा आनंद घेण्यासाठी वेळ काढण्यासाठी एक दिवस आगाऊ तयार करा. आपल्या दिवसाची सुरुवात करण्यासाठी, आपल्या दिवसाची योजना करण्यासाठी आणि आपल्या दिवसाचा आनंद घेण्यासाठी वेळ काढण्यासाठी एक दिवस आगाऊ तयार करा.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "id": "rTR0Ms880AVH"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या कंपनीमध्ये नवीन कामगार सुरु करण्यास संदर्भात आपल्याला काय मार्गदर्शन देणार?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zooQYpPt0AP2",
        "outputId": "74d1f3ef-5dcb-4d3e-c14a-2007bc609fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या कंपनीमध्ये नवीन कामगार सुरु करण्यास संदर्भात आपल्याला काय मार्गदर्शन देणार?\\n\\n### Input:\\n\\n\\n### Response:\\nआमच्या कंपनीमध्ये नवीन कामगार सुरू करण्यासाठी, आम्ही आमच्या कर्मचार्\\u200dयांच्या प्रशिक्षण आणि विकासामध्ये गुंतवणूक करून आणि त्यांच्या प्रगतीचा मागोवा घेण्यासाठी आणि त्यांच्या यशाचे मूल्यांकन करण्यासाठी प्रोत्साहन देऊन मार्गदर्शन करू. आम्ही नवीन कर्मचार्\\u200dयांना कंपनीच्या संस्कृतीबद्दल आणि त्यांच्या भूमिकांबद्दल अधिक जाणून घेण्यासाठी संसाधने देखील प्रदान करू.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "id": "zooQYpPt0AP2"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या कौशल्यांमध्ये विकास कसे करणार? आपण कशासाठी संग्रहणा करावी आणि कसे स्वतंत्रता संग्रहीत करावी?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQQi2vTw0AJ-",
        "outputId": "879c1791-ff14-4ecd-a470-53da9e5d70af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या कौशल्यांमध्ये विकास कसे करणार? आपण कशासाठी संग्रहणा करावी आणि कसे स्वतंत्रता संग्रहीत करावी?\\n\\n### Input:\\n\\n\\n### Response:\\nआमच्या कौशल्यांमध्ये विकास करण्यासाठी, आपण आपल्या कौशल्यांच्या विस्तृत श्रेणीचा शोध घेणे आवश्यक आहे आणि आपल्या कौशल्यांच्या विस्तृत श्रेणीचा शोध घेणे आवश्यक आहे. आपण आपल्या कौशल्यांच्या विस्तृत श्रेणीचा शोध घेण्यासाठी आणि आपल्या कौशल्यांच्या विस्तृत श्रेणीचा शोध घेण्यासाठी संसाधने शोधू शकता. या संसाधनांमध्ये ऑनलाइन कोर्स घेणे, ऑनलाइन समुदाय सामील होणे, ऑनलाइन क्विझ घेणे, ऑनलाइन पॉडकास्ट ऐकणे, ऑनलाइन मंच तयार करणे आणि ऑनलाइन क्वेरी करणे यांचा समावेश होतो. याव्यतिरिक्त, आपण आपल्या कौशल्यांच्या विस्तृत श्रेणीचा शोध घेण्यासाठी आणि आपल्या कौशल्यांच्या विस्तृत श्रेणीचा शोध घेण्यासाठी स्वतंत्रता शोधू शकता. आपण स्वतंत्रपणे प्रकल्प किंवा प्रकल्पांवर काम करू शकता किंवा आपल्या कौशल्यांच्या विस्तृत श्रेणीचा शोध घेण्यासाठी इतर लोकांसह सहयोग करू शकता.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "id": "AQQi2vTw0AJ-"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"वायु प्रदूषणाचा कसा वाढ होतो आणि त्याच्याच परिणाम समजायला कसे मदत करावी?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWgQh2eu0AHY",
        "outputId": "3c8967b8-32da-48d0-80b2-5dec22c6513b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nवायु प्रदूषणाचा कसा वाढ होतो आणि त्याच्याच परिणाम समजायला कसे मदत करावी?\\n\\n### Input:\\n\\n\\n### Response:\\nवायु प्रदूषणाचा वाढ होतो कारण वाहने, उद्योग आणि इतर मानवी क्रियाकलापांमुळे वायूंचे उत्सर्जन होते. या वायूंच्या उत्सर्जनामुळे हवेची गुणवत्ता कमी होऊ शकते आणि श्वास घेण्यायोग्य वायूंच्या पातळीत वाढ होऊ शकते. यामुळे श्वसनाचे आजार, कर्करोग आणि हृदयरोग यासारख्या आरोग्य समस्या उद्भवू शकतात. याव्यतिरिक्त, वायू प्रदूषणामुळे पर्यावरणावर नकारात्मक परिणाम होऊ शकतात जसे की हवामानातील बदल आणि जैवविविधतेतील घट.\\n\\nवायू प्रदूषण कमी करण्यासाठी, सरकारने उत्सर्जन मानके लागू केले पाहिजेत आणि वाहने आणि इतर वाहनांच्या उत्सर्जनासाठी कठोर नियम लागू केले पाहिजेत. याव्यतिरिक्त, सार्वजनिक वाहतूक आणि इलेक्ट्रिक वाहनांच्या वापरास प्रोत्साहन देण्यासाठी सरकारने प्रोत्साहन दिले पाहिजे. याव्यतिरिक्त, वायू प्रदूषणाचे परिणाम कमी करण्यासाठी व्यक्ती आणि व्यवसायांनी त्यांच्या स्वतःच्या पद्धती वापरल्या पाहिजेत जसे की इलेक्ट्रिक वाहने आणि सार्वजनिक वाहतूक वापरणे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "id": "UWgQh2eu0AHY"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"जलवायू परिवर्तनाचा कसा परिणाम असतो आणि साधारण लोकांना याबाबत कसे शिकवावं?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1gdTzWY0AEk",
        "outputId": "b598c38f-6322-474f-96a4-4b550712154d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nजलवायू परिवर्तनाचा कसा परिणाम असतो आणि साधारण लोकांना याबाबत कसे शिकवावं?\\n\\n### Input:\\n\\n\\n### Response:\\nजलवायू परिवर्तनाचा परिणाम असा होतो की समुद्रातील आम्लता वाढते, ज्यामुळे वन्यजीवांना अत्यंत हानिकारक परिस्थितीचा सामना करावा लागतो. यामुळे वन्यजीवांच्या प्रजाती नष्ट होण्याचा धोका देखील वाढतो, कारण काही प्रजाती त्यांच्या वातावरणातील बदलांना अधिक चांगल्या प्रकारे जुळवून घेण्यास सक्षम नाहीत.\\n\\nजलवायू परिवर्तनाचा लोकांना देखील परिणाम होतो, कारण ते त्यांच्या पाण्याच्या स्त्रोतांच्या गुणवत्तेवर परिणाम करू शकते आणि त्यांच्या आरोग्यावर परिणाम करू शकते. यामुळे पाण्याची कमतरता देखील होऊ शकते, ज्यामुळे अन्न उत्पादन कमी होऊ शकते आणि अन्न असुरक्षितता वाढू शकते.\\n\\nजलवायू परिवर्तनाचा सामना करण्यासाठी, लोक त्यांच्या पाण्याचा वापर कमी करून आणि पाण्याचा अपव्यय कमी करून त्यांच्या पाण्याचा वापर कमी करू शकतात. याव्यतिरिक्त, लोक त्यांच्या पाण्याचा वापर कमी करण्यासाठी आणि त्यांच्या पाण्याचा अपव्यय कमी करण्यासाठी शाश्वत पद्धतींचा अवलंब करू शकतात जसे की पाणी-कार्यक्षम उपकरणे वापरणे, पाणी-कार्यक्षम वाहने वापरणे आणि पाणी-कार्यक्षम वाहने वापरणे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "id": "K1gdTzWY0AEk"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"त्यांच्या स्वरूपात संकट असणाऱ्या जैविक संसाधनांचा समर्थन कसा करावा?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz9EPMya5Bcc",
        "outputId": "a0efacd4-142c-4dca-cee0-691673ae3ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nत्यांच्या स्वरूपात संकट असणाऱ्या जैविक संसाधनांचा समर्थन कसा करावा?\\n\\n### Input:\\n\\n\\n### Response:\\nजैविक संसाधनांच्या संकटाचा समावेश असलेल्या प्रजातींच्या संरक्षणासाठी, संवर्धन आणि संरक्षण उपाययोजना करणे आवश्यक आहे. यामध्ये संसाधनांच्या वापराचे नियमन करणे, शाश्वत पद्धतींचा अवलंब करणे आणि संसाधनांचे संरक्षण करण्यासाठी कायदेशीर उपाययोजना करणे समाविष्ट आहे. याव्यतिरिक्त, संसाधनांच्या संकटाचा सामना करण्यासाठी संस्था आणि व्यक्तींनी संसाधनांच्या वापराचे निरीक्षण करणे आणि त्यांच्या संसाधनांचे संरक्षण करण्यासाठी कृती करणे आवश्यक आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "id": "qz9EPMya5Bcc"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"जलवायू परिणामांच्या समर्थनासाठी कसा कृषी विकास करावा?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si7M20s7z__5",
        "outputId": "5972169e-3485-4389-83ce-1f3315f6053a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nजलवायू परिणामांच्या समर्थनासाठी कसा कृषी विकास करावा?\\n\\n### Input:\\n\\n\\n### Response:\\nजलवायू परिणामांच्या समर्थनासाठी कृषी विकासामध्ये अनेक पावले उचलली पाहिजेत. प्रथम, कृषी पद्धतींचा पर्यावरणावर होणारा परिणाम कमी करण्यासाठी संशोधन आणि तंत्रज्ञानाचा वापर केला पाहिजे. दुसरे म्हणजे, कृषी पद्धतींच्या परिणामांचा अंदाज घेण्यासाठी आणि कमी करण्यासाठी मॉडेल्स विकसित केले पाहिजेत. तिसरे म्हणजे, कृषी पद्धतींच्या परिणामांचा अंदाज लावण्यासाठी आणि कमी करण्यासाठी डेटाचे विश्लेषण केले पाहिजे. शेवटी, कृषी पद्धतींच्या परिणामांचा अंदाज लावण्यासाठी आणि कमी करण्यासाठी धोरणे विकसित केली पाहिजेत.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "id": "si7M20s7z__5"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"वनस्पतींच्या लवकरात कसा दुर्बली करावी आणि त्यांची संरक्षण कसे करावे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCfobzTdz_9b",
        "outputId": "ce2b4fd5-769f-41bd-b518-be1bb85dbfc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nवनस्पतींच्या लवकरात कसा दुर्बली करावी आणि त्यांची संरक्षण कसे करावे?\\n\\n### Input:\\n\\n\\n### Response:\\nवनस्पतींच्या लवकरात कसा दुर्बली करावी आणि त्यांच्या संरक्षणासाठी काय केले पाहिजे यासाठी काळजीपूर्वक नियोजन आणि तयारी आवश्यक आहे. वनस्पतींच्या लवकरात कसे कमी करायचे यासाठी, वनस्पतींच्या लवकरात कमी करण्यासाठी आणि त्यांच्या संरक्षणासाठी काही पावले उचलली पाहिजेत.\\n\\nप्रथम, वनस्पतींच्या लवकरात कमी करण्यासाठी, वनस्पतींच्या लवकरात कमी करण्यासाठी आणि त्यांच्या संरक्षणासाठी काही पावले उचलली पाहिजेत. यामध्ये वनस्पतींच्या लवकरात कमी करण्यासाठी आणि त्यांच्या संरक्षणासाठी काही पावले उचलण्यासाठी सराव करणे समाविष्ट असू शकते.\\n\\nयामध्ये वनस्पतींच्या लवकरात कमी करण्यासाठी आणि त्यांच्या संरक्षणासाठी काही पावले उचलण्यासाठी सराव करणे समाविष्ट असू शकते. यामध्ये वनस्पतींच्या लवकरात कमी करण्यासाठी आणि त्यांच्या संरक्षणासाठी काही पावले उचलण्यासाठी सराव करणे समाविष्ट असू शकते.\\n\\nवनस्पतींच्या लवकरात कमी करण्यासाठी आणि त्यांच्या संरक्षणासाठी काही पावले उचलण्यासाठी सराव करण्यासाठी, वनस्पतींच्या लवकरात कमी करण्यासाठी आणि त्यांच्या संरक्षणासाठी काही पावले उचलण्यासाठी सराव करण्यासाठी काही पावले उचलली पाहिजेत.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "id": "GCfobzTdz_9b"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या संघटनेचा पर्यावरणीय प्रभाव कसा निर्माण करावा आणि समुदायात कसे जाण घ्यावं?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "235z6fr95Bs5",
        "outputId": "3ade9b18-f761-406d-e232-e80b5e3a7775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या संघटनेचा पर्यावरणीय प्रभाव कसा निर्माण करावा आणि समुदायात कसे जाण घ्यावं?\\n\\n### Input:\\n\\n\\n### Response:\\nआमच्या संस्थेचा पर्यावरणीय प्रभाव कमी करण्यासाठी आणि समुदायात जाण्यासाठी, आम्ही अनेक पावले उचलू शकतो. प्रथम, आम्ही ऊर्जेचा वापर कमी करण्यासाठी आणि कमी वाहतूक करण्यासाठी प्रयत्न केले पाहिजेत. आम्ही कमी पॅकेजिंग आणि पुनर्वापर केलेल्या सामग्रीचा वापर करून आणि कमी प्लास्टिक आणि पुनर्वापर केलेल्या सामग्रीचा वापर करून कचरा कमी करण्यासाठी प्रयत्न केले पाहिजेत. आम्ही अक्षय ऊर्जा स्त्रोतांचा वापर करून आणि शाश्वत पद्धतींचा अवलंब करून हवामान बदलाविरुद्ध लढा दिला पाहिजे. शेवटी, आम्ही आमच्या कर्मचार्\\u200dयांना पर्यावरणीय प्रयत्नांमध्ये सहभागी होण्यासाठी प्रोत्साहित केले पाहिजे आणि आमच्या संस्थेच्या पर्यावरणीय प्रयत्नांबद्दल जागरूकता पसरवली पाहिजे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "id": "235z6fr95Bs5"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"पाण्याच्या गोष्टीत कसा बदल करावं आणि शहरातील नद्यांच्या सुरक्षिततेचा कसा साधारण करावा?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkz5hb4d5Bq3",
        "outputId": "82b52fae-f5d2-413f-87b7-a6a57b9d85cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nपाण्याच्या गोष्टीत कसा बदल करावं आणि शहरातील नद्यांच्या सुरक्षिततेचा कसा साधारण करावा?\\n\\n### Input:\\n\\n\\n### Response:\\nपाण्याच्या गोष्टीत बदल करण्यासाठी आणि शहरातील नद्यांच्या सुरक्षिततेला प्रोत्साहन देण्यासाठी, शहराने नद्यांच्या सद्यस्थितीचे मूल्यांकन केले पाहिजे आणि नद्यांच्या सुरक्षिततेला प्रोत्साहन देण्यासाठी धोरणे विकसित केली पाहिजेत. या धोरणांमध्ये नद्यांच्या सद्यस्थितीचे मूल्यांकन करणे, नद्यांच्या सुरक्षिततेला प्रोत्साहन देण्यासाठी धोरणे विकसित करणे आणि नद्यांच्या सुरक्षिततेला प्रोत्साहन देण्यासाठी धोरणांचे अंमलबजावणी करणे समाविष्ट असू शकते.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "id": "mkz5hb4d5Bq3"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"तुमच्या घरात साधारण जलवायू चांगला कसा करावा आणि ऊर्जा खर्च कसे कमी करावे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Bz_P2u5Bmg",
        "outputId": "688b799c-205f-4598-a322-b01a1200551f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nतुमच्या घरात साधारण जलवायू चांगला कसा करावा आणि ऊर्जा खर्च कसे कमी करावे?\\n\\n### Input:\\n\\n\\n### Response:\\nतुमच्या घरात जलवायू चांगला करण्यासाठी आणि ऊर्जा खर्च कमी करण्यासाठी, तुम्ही अनेक पावले उचलू शकता. प्रथम, तुम्ही तुमच्या घरातील पाणी-कार्यक्षम उपकरणे आणि फिक्स्चर स्थापित केले पाहिजेत. यामध्ये शॉवरहेड्स आणि नल एरेटर यांसारख्या ऊर्जा-कार्यक्षम फिक्स्चरचा समावेश असेल. याव्यतिरिक्त, तुम्ही तुमच्या घरातील पाणी वाचवण्यासाठी तुम्ही वापरत असलेल्या पाण्याचा वापर कमी करण्यासाठी तुम्ही तुमचा शॉवर घेण्याचा वेळ आणि वारंवारता कमी करू शकता. तुम्ही तुमच्या घरातील पाणी वाचवण्यासाठी तुम्ही तुमचा पाणी वापर कमी करण्यासाठी तुम्ही वापरत असलेल्या पाण्याचा वापर कमी करण्यासाठी तुम्ही तुमच्या घरातील पाणी-कार्यक्षम उपकरणे देखील वापरू शकता. शेवटी, तुम्ही तुमच्या घरातील पाणी वाचवण्यासाठी तुम्ही तुमच्या घरातील पाणी-कार्यक्षम उपकरणे देखील वापरू शकता.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "id": "J9Bz_P2u5Bmg"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"तुमच्या व्यवसायात पर्यावरणीय सुरक्षिततेचा कसा प्रभाव करावा आणि साधारण जनतेला याबाबत कसे सशिक्षित करावं?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtPPeQAx5Bjs",
        "outputId": "326160b2-6f2b-4788-a8ca-8c040502c621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nतुमच्या व्यवसायात पर्यावरणीय सुरक्षिततेचा कसा प्रभाव करावा आणि साधारण जनतेला याबाबत कसे सशिक्षित करावं?\\n\\n### Input:\\n\\n\\n### Response:\\nतुमच्या व्यवसायात पर्यावरणीय सुरक्षा महत्त्वाची आहे कारण ते आपल्याला आपल्या ग्रहाचे रक्षण करण्यास मदत करण्यासाठी आपल्या कचरा कमी करण्यासाठी आणि कमी करण्यासाठी प्रयत्न करण्यास प्रेरित करते. याव्यतिरिक्त, पर्यावरणीय सुरक्षा व्यवसायांना त्यांच्या कचरा कमी करण्याच्या प्रयत्नांना प्रोत्साहन देते आणि त्यांच्या पर्यावरणीय प्रभाव कमी करण्यासाठी त्यांच्या प्रयत्नांच्या परिणामांबद्दल जागरूकता वाढवते.\\n\\nतुमच्या व्यवसायाने त्यांच्या कचरा कमी करण्यासाठी आणि पर्यावरणीय प्रभाव कमी करण्यासाठी प्रयत्न केले पाहिजेत. यामध्ये कचरा कमी करण्यासाठी प्रक्रियांची अंमलबजावणी करणे, कचरा कमी करण्यासाठी प्रोत्साहन देणे आणि कचरा कमी करण्यासाठी प्रोत्साहन देणे यांचा समावेश होतो. याव्यतिरिक्त, व्यवसायाने त्यांच्या कर्मचाऱ्यांना पर्यावरणीय सुरक्षा प्रोटोकॉल आणि त्यांच्या कचरा कमी करण्याच्या प्रयत्नांबद्दल शिक्षित केले पाहिजे आणि त्यांच्या कर्मचाऱ्यांना त्यांच्या कचरा कमी करण्याच्या प्रयत्नांबद्दल जागरूकता पसरवण्यासाठी प्रोत्साहित केले पाहिजे.\\n\\nयाव्यतिरिक्त, व्यवसायाने त्यांच्या पर्यावरणीय प्रभाव कमी करण्यासाठी आणि कमी करण्यासाठी प्रयत्न केले पाहिजेत. यामध्ये कचरा कमी करण्यासाठी प्रक्रियांची अंमलबजावणी करणे, कचरा कमी करण्यासाठी प्रोत्साहन देणे आणि कचरा कमी करण्यासाठी प्रोत्साहन देणे यांचा समावेश होतो. याव्यतिरिक्त, व्यवसायाने त्यांच्या कर्मचाऱ्यांना पर्यावरणीय सुरक्षा प्रोटोकॉल आणि त्यांच्या कचरा कमी करण्याच्या प्रयत्नांबद्दल जागरूकता पसरवण्यासाठी प्रोत्साहित केले पाहिजे आणि त्यांच्या कर्मचाऱ्यांना त्यांच्या कचरा कमी करण्याच्या प्रयत्नांबद्दल जागरूकता पसरवण्यासाठी प्रोत्साहित केले पाहिजे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "id": "BtPPeQAx5Bjs"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"शहरीकरणाचा कसा परिणाम असतो आणि त्याच्या पर्यावरणीय प्रभावांना कसे कमी करावं?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNM4BM-J5BhR",
        "outputId": "247e2c7e-5b25-4e12-b8f9-e25395e5bf47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nशहरीकरणाचा कसा परिणाम असतो आणि त्याच्या पर्यावरणीय प्रभावांना कसे कमी करावं?\\n\\n### Input:\\n\\n\\n### Response:\\nशहरीकरणामुळे हवामान बदलास हातभार लागतो कारण ते वायू प्रदूषण वाढवते आणि जंगलांचे नुकसान करून हवामानातील बदलांचा प्रसार करण्यास हातभार लावते. शहरीकरणामुळे हवामानातील बदलांच्या परिणामांचा सामना करण्यासाठी देखील संघर्ष होतो कारण शहरे अनेकदा कमी संसाधने असतात आणि त्यांच्याकडे कमी हिरवी जागा असतात. शहरीकरणामुळे नैसर्गिक परिसंस्थेलाही हानी पोहोचते कारण शहरे अनेकदा हिरवी जागा कमी करण्यासाठी आणि वाहतुकीसाठी अधिक जागा घेतात. शिवाय, शहरीकरणामुळे वायू प्रदूषण वाढते आणि हवामान बदलाचा प्रसार करण्यासाठी हवामान बदल कमी करण्यासाठी आवश्यक असलेल्या कार्यांवर लक्ष केंद्रित करण्यासाठी संसाधने कमी होऊ शकतात.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "id": "BNM4BM-J5BhR"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NlIkahs28eIf"
      },
      "id": "NlIkahs28eIf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J1TpO2ho8eFh"
      },
      "id": "J1TpO2ho8eFh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "voEWwMcW8eCz"
      },
      "id": "voEWwMcW8eCz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqo2xK3u8d_w"
      },
      "id": "eqo2xK3u8d_w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nki_sHh-8d82"
      },
      "id": "Nki_sHh-8d82",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oZhuV3WD8d6R"
      },
      "id": "oZhuV3WD8d6R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NilHdGf48d3h"
      },
      "id": "NilHdGf48d3h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OpxM-GAX8d04"
      },
      "id": "OpxM-GAX8d04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GjcX358U8dyJ"
      },
      "id": "GjcX358U8dyJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCzJ_Pzb8dvS"
      },
      "id": "gCzJ_Pzb8dvS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9QRm35SO8dsY"
      },
      "id": "9QRm35SO8dsY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAA11Esh8dp2"
      },
      "id": "eAA11Esh8dp2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSuSOg_D8dnQ"
      },
      "id": "qSuSOg_D8dnQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z3FEa-Jq8dkH"
      },
      "id": "Z3FEa-Jq8dkH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "El1oVrCB8dhG"
      },
      "id": "El1oVrCB8dhG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mp5vxQe8dd5"
      },
      "id": "3mp5vxQe8dd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3c7DJ48G8dbd"
      },
      "id": "3c7DJ48G8dbd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yu2r2UL68dYS"
      },
      "id": "Yu2r2UL68dYS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c936meZc8dVI"
      },
      "id": "c936meZc8dVI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mTpA85vD8dSr"
      },
      "id": "mTpA85vD8dSr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w81_Ag8M8dPu"
      },
      "id": "w81_Ag8M8dPu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t8OatePV8dNC"
      },
      "id": "t8OatePV8dNC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNFRxwOx8dKP"
      },
      "id": "YNFRxwOx8dKP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mV95QO6N8dG6"
      },
      "id": "mV95QO6N8dG6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "benc142U8dDw"
      },
      "id": "benc142U8dDw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LUNETlqu8dBG"
      },
      "id": "LUNETlqu8dBG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nalaBMxZ8c-R"
      },
      "id": "nalaBMxZ8c-R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jjjeoRbA8c7a"
      },
      "id": "jjjeoRbA8c7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iBcuNeTD8c3z"
      },
      "id": "iBcuNeTD8c3z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ASGASjAD8c05"
      },
      "id": "ASGASjAD8c05",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ykXoRbEH8cvo"
      },
      "id": "ykXoRbEH8cvo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vHiTKhdp8cs2"
      },
      "id": "vHiTKhdp8cs2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2MxlB7o8cqO"
      },
      "id": "a2MxlB7o8cqO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MRr5ov2T8cnY"
      },
      "id": "MRr5ov2T8cnY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3leXg6od8ck2"
      },
      "id": "3leXg6od8ck2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EC8RiphU8ch4"
      },
      "id": "EC8RiphU8ch4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ug3JzdVQ8cfH"
      },
      "id": "ug3JzdVQ8cfH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BTJX4N6p8ccR"
      },
      "id": "BTJX4N6p8ccR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jfpqyMYe8cZk"
      },
      "id": "jfpqyMYe8cZk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BfhuuHXH8cWx"
      },
      "id": "BfhuuHXH8cWx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hn0cEsyB8cUF"
      },
      "id": "hn0cEsyB8cUF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XJydIz6t8cRL"
      },
      "id": "XJydIz6t8cRL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYGLvXDy8cOq"
      },
      "id": "IYGLvXDy8cOq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_1cEKcB88cL5"
      },
      "id": "_1cEKcB88cL5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_XZUV5Cv8cJU"
      },
      "id": "_XZUV5Cv8cJU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6d7qXXe8cGt"
      },
      "id": "G6d7qXXe8cGt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sB9hFkhi8cEP"
      },
      "id": "sB9hFkhi8cEP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7IFkm_Ed8b8o"
      },
      "id": "7IFkm_Ed8b8o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQpxHbqN8b6Y"
      },
      "id": "jQpxHbqN8b6Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D006O6658b3e"
      },
      "id": "D006O6658b3e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UG32uvAq8b0z"
      },
      "id": "UG32uvAq8b0z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fB1BZrxs8bwb"
      },
      "id": "fB1BZrxs8bwb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HxXfW9a68btY"
      },
      "id": "HxXfW9a68btY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H9aUvJcP8bqt"
      },
      "id": "H9aUvJcP8bqt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6raIBAgW8bnz"
      },
      "id": "6raIBAgW8bnz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pw0rU0CM8bk4"
      },
      "id": "Pw0rU0CM8bk4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_zasJxp8biC"
      },
      "id": "n_zasJxp8biC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c4ybq8kX8bfV"
      },
      "id": "c4ybq8kX8bfV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLqDQhqM8bc5"
      },
      "id": "LLqDQhqM8bc5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOHuWbj_8baD"
      },
      "id": "TOHuWbj_8baD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57PVvAAw8bXK"
      },
      "id": "57PVvAAw8bXK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S37T9hOL8bUU"
      },
      "id": "S37T9hOL8bUU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "67f0f405",
      "metadata": {
        "id": "67f0f405"
      },
      "source": [
        "##### Example-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7623fee4-ba70-4aaf-85c1-f12bd73aa5b8",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7623fee4-ba70-4aaf-85c1-f12bd73aa5b8",
        "outputId": "2225b80c-fefe-4ed1-c518-e79053d78382"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\n(9+0)+(10+5)? 3 चरणांमध्ये सोडवा\\n\\n### Input:\\n\\n\\n### Response:\\n1. 9 + 0 = 9\\n2. 10 + 5 = 15\\n3. 15 + 15 = 30<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"(9+0)+(10+5)? 3 चरणांमध्ये सोडवा\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"पक्ष्यांवर निबंध लिहा\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrFCL3wsu4Dk",
        "outputId": "3d0bae8d-daad-4920-e2f4-8586b780f80f"
      },
      "id": "SrFCL3wsu4Dk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nपक्ष्यांवर निबंध लिहा\\n\\n### Input:\\n\\n\\n### Response:\\nपक्ष्यांच्या विविध प्रजातींच्या विविधतेचे सौंदर्य आणि सौंदर्य पाहून पाहणे ही एक अविस्मरणीय गोष्ट आहे. पक्ष्यांच्या विविध प्रजातींच्या विविधतेचा शोध घेण्यासाठी आपण जंगलातून फिरताना, शहरातील रस्त्यावरून चालताना किंवा शहरातील रस्त्यावरून फिरताना पक्ष्यांच्या आवाजाने आपला दिवस भरून काढला पाहिजे. पक्ष्यांच्या विविध प्रजातींच्या विविधतेचा शोध घेण्यासाठी आपण जंगलातून फिरताना, शहरातील रस्त्यावरून चालताना किंवा शहरातील रस्त्यावरून फिरताना पक्ष्यांच्या आवाजाने आपला दिवस भरून काढला पाहिजे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SBu2BhN5u4F1"
      },
      "id": "SBu2BhN5u4F1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"महाराष्ट्राची राजधानी काय आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8clwZ5_u4Ii",
        "outputId": "f90ec344-3c1e-4d5f-8887-0ae9621ad306"
      },
      "id": "t8clwZ5_u4Ii",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nमहाराष्ट्राची राजधानी काय आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nमहाराष्ट्राची राजधानी म्हणजे मुंबई.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"अमेरिकेची राजधानी काय आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1000, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSEVZkLlu4Ka",
        "outputId": "fd381766-37c8-42ee-a281-495c1cc1c840"
      },
      "id": "GSEVZkLlu4Ka",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nअमेरिकेची राजधानी काय आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nवॉशिंग्टन डीसी<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"फॅरेनहाइटमध्ये पाण्याचा उत्कलन बिंदू किती आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 100, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAHZy3_MTDgX",
        "outputId": "80845d6e-e944-4bac-9b41-a14d9d93cd65"
      },
      "id": "vAHZy3_MTDgX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nफॅरेनहाइटमध्ये पाण्याचा उत्कलन बिंदू किती आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nफॅरेनहाइटमध्ये पाण्याचा उत्कलन बिंदू 100 अंश फॅरेनहाइट आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आपल्या सूर्यमालेतील सर्वात मोठा ग्रह कोणता आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 100, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAGUXpiiTDYo",
        "outputId": "e31fde51-d260-4dd2-a3a1-ca5de97779e3"
      },
      "id": "aAGUXpiiTDYo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआपल्या सूर्यमालेतील सर्वात मोठा ग्रह कोणता आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nआपल्या सूर्यमालेतील सर्वात मोठा ग्रह मंगळ आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"त्रिकोणाचे क्षेत्रफळ काढण्याचे सूत्र कोणते?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 100, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2qukUofTBnd",
        "outputId": "0bba8c0f-e1f6-47b0-b4c4-ff2366febafb"
      },
      "id": "o2qukUofTBnd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nत्रिकोणाचे क्षेत्रफळ काढण्याचे सूत्र कोणते?\\n\\n### Input:\\n\\n\\n### Response:\\nत्रिकोणाचे क्षेत्रफळ काढण्याचे सूत्र A = 1/2 * पाया * उंची आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"पृथ्वीवरील सर्वाधिक लांब नदी कोणती आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 100, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "E2oGXfXzwInZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71030bb5-192a-4f33-f2e4-802691eb7ac6"
      },
      "id": "E2oGXfXzwInZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nपृथ्वीवरील सर्वाधिक लांब नदी कोणती आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nपृथ्वीवरील सर्वात लांब नदी नाईल नदी आहे, ती सुमारे 4,132 किमी (2,510 मैल) लांब आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारतातील सर्वाधिक लोकप्रिय महाराष्ट्रीय संगीतकार कोण आहे? त्याचे व्यक्तिमत्व, संगीतीची शैली आणि काम त्याच्या लोकप्रियतेत कसे वाढतात, हे समजून घ्या.\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 100, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDCDO1snV09t",
        "outputId": "3aa6a5b6-ca01-462b-aad1-b9f63930c266"
      },
      "id": "EDCDO1snV09t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारतातील सर्वाधिक लोकप्रिय महाराष्ट्रीय संगीतकार कोण आहे? त्याचे व्यक्तिमत्व, संगीतीची शैली आणि काम त्याच्या लोकप्रियतेत कसे वाढतात, हे समजून घ्या.\\n\\n### Input:\\n\\n\\n### Response:\\nभारतातील सर्वाधिक लोकप्रिय महाराष्ट्रीय संगीतकार लिली-ओ-ली आहेत. त्यांच्या संगीताची शैली म्हणजे हिप-हॉप आणि पॉप, ज्याला \"पॉप-हिप\" म्हणूनही संबोधले जाते. त्यांच्या कामात अनेकदा विनोदी आणि विनोदी घटक असतात, ज्यामुळे ते लोकप्र']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"भारताच्या इतिहासातील महत्त्वाच्या त्रासदी व विजय संदर्भात, महाराष्ट्रातील छत्रपती शिवाजी महाराजांचं कौटुंबिक परिचय आणि त्यांच्या कार्याची विशेषता काय आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 100, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXY6xYnuV03y",
        "outputId": "6e3e305a-35b6-453c-8004-62eaad781d8f"
      },
      "id": "WXY6xYnuV03y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nभारताच्या इतिहासातील महत्त्वाच्या त्रासदी व विजय संदर्भात, महाराष्ट्रातील छत्रपती शिवाजी महाराजांचं कौटुंबिक परिचय आणि त्यांच्या कार्याची विशेषता काय आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nमहाराष्ट्रातील छत्रपती शिवाजी महाराजांचा जन्म 1645 मध्ये पश्चिम भारतातील मारिवाड्या येथे झाला होता आणि त्यांच्या वडीलांच्या पश्चात्तापांमुळे त्यांच्या कुटुंबाला बळी पडले होते. त्यांच्या वडीलांच्या मृत्यूनंतर, शि']"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"जगातील सर्वात मोठा सस्तन प्राणी कोणता आहे?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 100, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "BxxFN3dxV01r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3663fa-47bb-4ebb-a7b9-63c602ee0a9a"
      },
      "id": "BxxFN3dxV01r",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nजगातील सर्वात मोठा सस्तन प्राणी कोणता आहे?\\n\\n### Input:\\n\\n\\n### Response:\\nजगातील सर्वात मोठा सस्तन प्राणी हत्ती आहे.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"आधुनिक भौतिकशास्त्राचे जनक कोणाला मानले जाते?\",\n",
        "        \"\",\n",
        "        \"\"\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 100, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "olYqaVs8V0yo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4abb2521-8807-450b-d897-c01be01110e2"
      },
      "id": "olYqaVs8V0yo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>\\n### Instruction:\\nआधुनिक भौतिकशास्त्राचे जनक कोणाला मानले जाते?\\n\\n### Input:\\n\\n\\n### Response:\\nआधुनिक भौतिकशास्त्राचे जनक अल्बर्ट आइनस्टाईन मानले जातात.<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WxkaiGzzV0qu"
      },
      "id": "WxkaiGzzV0qu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5QG5m7s0V0lF"
      },
      "id": "5QG5m7s0V0lF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b928fc76f834f5d9a22647bf1908c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12817bf74b8448eb955d32b7ddcbdb79",
              "IPY_MODEL_94a12b94dbd246959f0974077dc76fac",
              "IPY_MODEL_2539d614c10e4ae3bf38b6ecf7e360c8",
              "IPY_MODEL_8667b1b65aac412babfbe4b947553e70"
            ],
            "layout": "IPY_MODEL_542bd0991b054025a7987313533598b6"
          }
        },
        "df535b43393845b087bbcbaa30dd8c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e30406f0bb4a4033855cfcd919174591",
            "placeholder": "​",
            "style": "IPY_MODEL_c1bcea450b2242609e1f479e99c6eb8b",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "c282afaf8a6f4b4f859b6e78641d35d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_62046bc7388a4748a22c0d0e95cdc991",
            "placeholder": "​",
            "style": "IPY_MODEL_737264a4d1af4905baaebf549250c29a",
            "value": ""
          }
        },
        "0d14aa4b1ea5414b927d70f2d692c306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_10935ba1cf85451e896b65aa798b5437",
            "style": "IPY_MODEL_2c9937d750c84e249096b8fa8f1a7422",
            "value": true
          }
        },
        "4279b863d26d42ff81dc6473c319e091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_59bf2cb7513442c5b11dd6623b65905e",
            "style": "IPY_MODEL_990e3816a51c467686bad25268ff2d03",
            "tooltip": ""
          }
        },
        "f0b911bfbc354ccc90ed3d9b07458f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdc9e836f99b41f98c04e617470d14fa",
            "placeholder": "​",
            "style": "IPY_MODEL_ea7dd54426e747209934832dd0cf451c",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "542bd0991b054025a7987313533598b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e30406f0bb4a4033855cfcd919174591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1bcea450b2242609e1f479e99c6eb8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62046bc7388a4748a22c0d0e95cdc991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "737264a4d1af4905baaebf549250c29a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10935ba1cf85451e896b65aa798b5437": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9937d750c84e249096b8fa8f1a7422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59bf2cb7513442c5b11dd6623b65905e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990e3816a51c467686bad25268ff2d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "fdc9e836f99b41f98c04e617470d14fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7dd54426e747209934832dd0cf451c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05073e6c5ec24c4c8f8e1d7f4cf1738c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_825c70bb965f4478aa2ee67fd906ba04",
            "placeholder": "​",
            "style": "IPY_MODEL_7fb04f1906ad4f148eb317e294adaeca",
            "value": "Connecting..."
          }
        },
        "825c70bb965f4478aa2ee67fd906ba04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb04f1906ad4f148eb317e294adaeca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f496c15e64bd4ea2819cc385ace39d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_504acc2cad154b1bae9774e3d780ebb1",
            "placeholder": "​",
            "style": "IPY_MODEL_4178034e006d40e1a681b302a2c96568",
            "value": "Token is valid (permission: read)."
          }
        },
        "b3a5c18bfcf0490f871837b00b8b49ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e447d4b89f64cb09e9d9f7203160b6e",
            "placeholder": "​",
            "style": "IPY_MODEL_7da167eb7d5e4f27a19b492b1c9015a8",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "f606abc4236d42b08d65ef04a158cf3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3292d7b49694c68b59ef7d30e26bcac",
            "placeholder": "​",
            "style": "IPY_MODEL_65dbf58c30154a638c4ff2529193aa3e",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "f522e047cb5c48e7ad3ef910e8b25d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7102b0115a2475c8802f5899531fd03",
            "placeholder": "​",
            "style": "IPY_MODEL_0277f13a4dc9411dafaf45fb6e328bf0",
            "value": "Login successful"
          }
        },
        "504acc2cad154b1bae9774e3d780ebb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4178034e006d40e1a681b302a2c96568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e447d4b89f64cb09e9d9f7203160b6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da167eb7d5e4f27a19b492b1c9015a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3292d7b49694c68b59ef7d30e26bcac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65dbf58c30154a638c4ff2529193aa3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7102b0115a2475c8802f5899531fd03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0277f13a4dc9411dafaf45fb6e328bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5176c23a0f2d4972aae1d1164df26a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef9b718d5c148b88c891b0b610b4106",
            "placeholder": "​",
            "style": "IPY_MODEL_4daf13b7084b456db738d0a41f294c7c",
            "value": "Connecting..."
          }
        },
        "eef9b718d5c148b88c891b0b610b4106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4daf13b7084b456db738d0a41f294c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12817bf74b8448eb955d32b7ddcbdb79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_672d75d606b64ea1a1fd14a74595566d",
            "placeholder": "​",
            "style": "IPY_MODEL_01bea79d11ff431297b907387b940b27",
            "value": "Token is valid (permission: read)."
          }
        },
        "94a12b94dbd246959f0974077dc76fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d972984d5384d5eb047d0833a5202f6",
            "placeholder": "​",
            "style": "IPY_MODEL_8ff5da450c86451294855fb6e5faf9ef",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "2539d614c10e4ae3bf38b6ecf7e360c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1baebae1044cffaf4f85a6eab78cf7",
            "placeholder": "​",
            "style": "IPY_MODEL_fd3074e3def8403386778fdd7ae031d1",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "8667b1b65aac412babfbe4b947553e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50eea668c45545369202083f72c0e97c",
            "placeholder": "​",
            "style": "IPY_MODEL_194f52587e744de29bac1ab9e8ffd4ae",
            "value": "Login successful"
          }
        },
        "672d75d606b64ea1a1fd14a74595566d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01bea79d11ff431297b907387b940b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d972984d5384d5eb047d0833a5202f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ff5da450c86451294855fb6e5faf9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1baebae1044cffaf4f85a6eab78cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3074e3def8403386778fdd7ae031d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50eea668c45545369202083f72c0e97c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194f52587e744de29bac1ab9e8ffd4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5251f2b5fa2e4ddcafc3ac0aa46dc909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_634f934513dc465f990362f3e320ff94",
              "IPY_MODEL_213f705b215f41aa9c378fc7f049c067",
              "IPY_MODEL_544289e107fd4d4ca081c456a18cfe0e"
            ],
            "layout": "IPY_MODEL_9ea2e58baead4d50b7bc367c36f50aa6"
          }
        },
        "634f934513dc465f990362f3e320ff94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2304aa50af6a4666879cadd8eb8021a3",
            "placeholder": "​",
            "style": "IPY_MODEL_da9f4f5410e94bf68ece02a82cb0f1f8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "213f705b215f41aa9c378fc7f049c067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab32871895a2446297f4a15f415d4340",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f516f2ad31ac41e4af4731f3fefd933f",
            "value": 4
          }
        },
        "544289e107fd4d4ca081c456a18cfe0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba1a3c05d584f6ab4893bf738fb9490",
            "placeholder": "​",
            "style": "IPY_MODEL_315148985681451fa52a4e8e3a7d94f6",
            "value": " 4/4 [00:06&lt;00:00,  1.60s/it]"
          }
        },
        "9ea2e58baead4d50b7bc367c36f50aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2304aa50af6a4666879cadd8eb8021a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da9f4f5410e94bf68ece02a82cb0f1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab32871895a2446297f4a15f415d4340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f516f2ad31ac41e4af4731f3fefd933f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ba1a3c05d584f6ab4893bf738fb9490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315148985681451fa52a4e8e3a7d94f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}